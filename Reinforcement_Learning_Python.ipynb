{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "878c26bf",
   "metadata": {},
   "source": [
    "# Reinforcement Learning Python Project\n",
    "### Building a Machine Learning Model\n",
    "\n",
    "**Q Learning** Algorithm is used for the  model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d79544",
   "metadata": {},
   "source": [
    "#### Algorithm\n",
    "- Initialise the **Q-table** to all zeros\n",
    "- Iterate\n",
    "    - Agent is in state **state**.\n",
    "    - With probability **epsilon** choose to **explore**, else **exploit**.\n",
    "        - If **explore**, then choose a *random* **action**.\n",
    "        - If **exploit**, then choose the *best* **action** based on the current **Q-table**.\n",
    "    - Update the **Q-table** from the new **reward** to the previous state.\n",
    "    - Q[**state, action**] = (1 – **alpha**) * Q[**state, action**] + **alpha** * (**reward + gamma** * max(Q[**new_state**]) — Q[**state, action**])\n",
    "    \n",
    "#### Variables\n",
    "As you can se, we have introduced the following variables.\n",
    "\n",
    "- **epsilon**: the probability to take a random action, which is done to explore new territory.\n",
    "- **alpha**: is the learning rate that the algorithm should make in each iteration and should be in the interval from 0 to 1.\n",
    "- **gamma**: is the discount factor used to balance the immediate and future reward. This value is usually between 0.8 and 0.99\n",
    "- **reward**: is the feedback on the action and can be any number. Negative is penalty (or punishment) and positive is a reward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982d1b15",
   "metadata": {},
   "source": [
    "### Description \n",
    "- To keep it simple, we create a field of size 10×10 positions. In that field there is an item that needs to be picked up and moved to a drop-off point.\n",
    "- At each position there are 6 different actions that can be taken.\n",
    "    - **Action 0**: Go South if on field.\n",
    "    - **Action 1**: Go North if on field.\n",
    "    - **Action 2**: Go East if on field (Please notice, I mixed up East and West (East is Left here)).\n",
    "    - **Action 3**: Go West if on field (Please notice, I mixed up East and West (West is right here)).\n",
    "\n",
    "    - **Action 4**: Pickup item (it can try even if it is not there)\n",
    "    - **Action 5**: Drop-off item (it can try even if it does not have it)\n",
    "- Based on these actions we will make a reward system.\n",
    "    - If the **agent** tries to go off the **field**, punish with **-10** in **reward**.\n",
    "    - If the **agent** makes a (legal) move, punish with **-1** in **reward**, as we do not want to encourage endless walking around.\n",
    "    - If the **agent** tries to pick up item, but it is not there or it has it already, punish with **-10** in **reward**.\n",
    "    - If the **agent** picks up the item correct place, **reward** with **20**.\n",
    "    - If **agent** tries to drop-off item in wrong place or does not have the item, punish with **-10** in **reward**.\n",
    "    - If the **agent** drops-off item in correct place, **reward** with **20**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b45a37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Field:\n",
    "    def __init__(self, size, item_pickup, item_drop_off, start_pos):\n",
    "        self.size = size\n",
    "        self.item_pickup = item_pickup\n",
    "        self.item_drop_off = item_drop_off\n",
    "        self.position = start_pos\n",
    "        self.item_in_car = False\n",
    "        \n",
    "    def get_number_of_states(self):\n",
    "        return self.size*self.size*self.size*self.size*2\n",
    "    \n",
    "    def get_state(self):\n",
    "        state = self.position[0]*self.size*self.size*self.size*2\n",
    "        state = state + self.position[1]*self.size*self.size*2\n",
    "        state = state + self.item_pickup[0]*self.size*2\n",
    "        state = state + self.item_pickup[1]*2\n",
    "        if self.item_in_car:\n",
    "            state = state +1\n",
    "        return state    \n",
    "        \n",
    "    def make_action(self, action): \n",
    "        (x, y) = self.position\n",
    "        if action == 0: #Go south\n",
    "            if y == self.size-1:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x, y+1)\n",
    "                return -1, False\n",
    "        \n",
    "        elif action == 1: #Go north\n",
    "            if y == 0:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x,y-1)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 2: #Go east\n",
    "            if x == 0:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x-1,y)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 3: #Go west\n",
    "            if x == self.size -1:\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.position = (x+1,y)\n",
    "                return -1, False\n",
    "            \n",
    "        elif action == 4: #pcikup item\n",
    "            if self.item_in_car:\n",
    "                return -10, False\n",
    "            elif self.item_pickup != (x,y):\n",
    "                return -10, False\n",
    "            else:\n",
    "                self.item_in_car = True\n",
    "                return 20, False\n",
    "            \n",
    "        elif action == 5: #Drop off\n",
    "            if not self.item_in_car:\n",
    "                return -10, False\n",
    "            elif self.item_drop_off != (x,y):\n",
    "                self.item_pickup = (x, y)\n",
    "                self.item_in_car = False\n",
    "                return -10, False\n",
    "            else:\n",
    "                return 20, True\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a58166f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a118f925",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10\n",
    "item_start = (0,0)\n",
    "item_drop_off = (9,9)\n",
    "start_pos = (0,9)\n",
    "    \n",
    "field = Field(size, item_start, item_drop_off, start_pos)\n",
    "\n",
    "number_of_states = field.get_number_of_states()\n",
    "number_of_actions = 6\n",
    "\n",
    "q_table = np.zeros((number_of_states, number_of_actions))\n",
    "\n",
    "epsilon = 0.1\n",
    "alpha = 0.1\n",
    "gamma = 0.6\n",
    "\n",
    "for _ in range(1000):\n",
    "    field = Field(size, item_start, item_drop_off, start_pos)\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        state = field.get_state()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = random.randint(0,5)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "            \n",
    "        reward, done = field.make_action(action) \n",
    "        #Q[state, action] = (1 – alpha) * Q[state, action] + alpha * (reward + gamma * max(Q[new_state]) — Q[state, action])\n",
    "        \n",
    "        new_state = field.get_state()\n",
    "        new_state_max = np.max(q_table[new_state])\n",
    "        q_table[state, action] = (1-alpha)*q_table[state, action] + alpha*(reward+gamma*new_state_max-q_table[state, action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fef4b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinforcement_learning():\n",
    "    epsilon = 0.1\n",
    "    alpha = 0.1\n",
    "    gamma = 0.6\n",
    "    \n",
    "    field = Field(size, item_start, item_drop_off, start_pos)\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    while not done:\n",
    "        state = field.get_state()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = random.randint(0,5)\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])\n",
    "            \n",
    "        reward, done = field.make_action(action) \n",
    "        #Q[state, action] = (1 – alpha) * Q[state, action] + alpha * (reward + gamma * max(Q[new_state]) — Q[state, action])\n",
    "        \n",
    "        new_state = field.get_state()\n",
    "        new_state_max = np.max(q_table[new_state])\n",
    "        q_table[state, action] = (1-alpha)*q_table[state, action] + alpha*(reward+gamma*new_state_max-q_table[state, action])\n",
    "        \n",
    "        steps = steps + 1\n",
    "        \n",
    "    return steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be111c",
   "metadata": {},
   "source": [
    "Running program to test how many steps to solve problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acea6ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinforcement_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19162d",
   "metadata": {},
   "source": [
    "Taking the average numbers of the step of 1000 tryings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dadd88f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.306"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_rl = [ reinforcement_learning() for _ in range(1000)]\n",
    "\n",
    "sum(runs_rl)/len(runs_rl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c292a38c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
